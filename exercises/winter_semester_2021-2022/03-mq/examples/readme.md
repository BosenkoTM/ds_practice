# Примеры использования очередей

## Rabbit MQ
Для начала нам надо запустить сам RabbitMQ. Для этого мы будем использовать
Docker.

```bash
$ docker run -d \
    --hostname rabbitmq \
    --log-driver=journald \
    --name rabbitmq \
    -p 5672:5672 \
    -p 15672:15672 \
    -p 15674:15674 \
    -p 25672:25672 \
    -p 61613:61613 \
    -v rabbitmq_data:/var/lib/rabbitmq \
    rabbitmq:3.6.14-management
```

Чтобы проверить, что он запустился, надо сходить на `http://localhost:15672` (порт RabbitMQ Management).

_Если он не запустился и вам лень разбираться, то можно воспользоваться бесплатным инстансом на https://cloudamqp.com, но для этого придётся самому разобраться, какие логины/пароли просунуть в sender/reciever._

Дальше нужно спуститься в директорию с примерами:

```bash
$ cd 04-mq/examples
$ pwd 
/home/<username>/04-mq/examples
```

На всякий случай установить несколько зависимостей:

```bash
$ pip install -r requirements.txt
```

Теперь можно запускать примеры и играться с ними. 

### `hello-world`

Первый пример очень простой. Сначала мы запускаем ресивер:

```
$ python hello-world/recieve.py
```

Затем

```
$ python hello-world/send.py
```

Здесь мы увидим вывод того, что сообщение отправилось, а потом, что сообщение
было доставлено.

Теперь давайте запустим несколько экземпляров `recieve.py`, и, после этого,
несколько раз запустим `send.py`. Мы увидим, что ресивер, принимающий сообщение, постоянно меняется. 

### `task-queue`

После освоения концепции queue-as-a-service принцип очереди задач должен быть понятен: заводим очередь задач `tasks`, в сообщения кладём тип задачи и данные, необходимые воркеру для выполнения задачи. Такая штука реализована в `task-queue`.

Можно немного усложнить эту концепцию, добавив вторую очередь — для результатов выполнения. Получится две очереди — одна для задач на выполнение удалёнными воркерами, а другая для результатов выполнения. Воркеры будут читать доступные задачи из очереди задач `tasks`, а результат класть в очередь `results`.  Писать в очередь `tasks` смогут много продьюсеров, а выполнять задачи, читая из очереди, сможет множество воркеров. Единственный ньюанс — результаты выполнения не будут сохраняться после чтения их кем-нибудь, а значит надо будет рассчитывать на это при построении вашего приложения.

<!-- Здесь бы картинку с одним продьюсером и большим количеством воркеров, которые берут задачи из очереди tasks и кладут результаты в очередь results -->

